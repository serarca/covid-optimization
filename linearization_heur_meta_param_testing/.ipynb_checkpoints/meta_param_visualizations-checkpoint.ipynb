{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipympl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-baaaa89d9ec4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'widget'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# matplotlib.use('Agg')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyter/hub/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2315\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-108>\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n",
      "\u001b[0;32m/opt/jupyter/hub/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyter/hub/lib/python3.6/site-packages/IPython/core/magics/pylab.py\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Available matplotlib backends: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbackends_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyter/hub/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36menable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   3417\u001b[0m                 \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3419\u001b[0;31m         \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate_matplotlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3420\u001b[0m         \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_inline_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyter/hub/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mactivate_matplotlib\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_needmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mswitch_backend\u001b[0;34m(newbackend)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylab_setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0m_backend_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_figure_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw_if_interactive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_show\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpylab_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/backends/__init__.py\u001b[0m in \u001b[0;36mpylab_setup\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# imports. 0 means only perform absolute imports.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     backend_mod = __import__(backend_name, globals(), locals(),\n\u001b[0;32m---> 60\u001b[0;31m                              [backend_name], 0)\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# Things we pull in from all backends\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipympl'"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import sys\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define set of all parameters and meta-parameters\n",
    "    parameters = {    \n",
    "    \"delta_schooling\":[0.5],\n",
    "        \"xi\":[0, 30 * 37199.03, 140 * 37199.03],\n",
    "#         , 140 * 37199.03],\n",
    "        \"icus\":[3000],\n",
    "        \"tests\":[0],\n",
    "        \"frequencies\":[(7,14)],\n",
    "        \"eta\":[0,0.1]\n",
    "    }\n",
    "    \n",
    "    meta_parameters = {\n",
    "        \"trust_region_radius\":[0,0.05,0.1,0.2,0.4,0.6],\n",
    "        \"max_inner_iterations_mult\":[1, 1.5, 2],\n",
    "        \"initial_uhat\":[\"dynamic_gradient\", \"full_lockdown\", \"full_open\"]\n",
    "    }\n",
    "    \n",
    "    n_days = 90\n",
    "    groups = \"all\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all data into one big pandas dataframe\n",
    "\n",
    "ls = []\n",
    "\n",
    "for delta in parameters[\"delta_schooling\"]:\n",
    "    for xi in parameters[\"xi\"]:\n",
    "        for icus in parameters[\"icus\"]:\n",
    "            for tests in parameters[\"tests\"]:\n",
    "                for freq in parameters[\"frequencies\"]:\n",
    "                    for eta in parameters[\"eta\"]:\n",
    "                        for initial_uhat in meta_parameters[\"initial_uhat\"]:\n",
    "                            with open(f\"testing_outputs_ndays={n_days}_eta={eta}_tests={tests}_xi={xi*10}_freq={freq[1]}_groups={groups}_initial_uhat={initial_uhat}_opt_bouncing=False.csv\", \"r\") as file:\n",
    "                                df = pd.read_csv(file, header=None, names=[\"radius\", \"factor\", \"num_iterations\", \"reward\", \"time\"])\n",
    "                            if len(df) == 0:\n",
    "                                print(file.name)\n",
    "                            df[\"delta\"] = delta\n",
    "                            df[\"xi\"] = xi\n",
    "                            df[\"icus\"] = icus\n",
    "                            df[\"tests\"] = tests\n",
    "                            df[\"freq\"] = freq[1]\n",
    "                            df[\"eta\"] = eta\n",
    "                            df[\"initial_uhat\"] = initial_uhat\n",
    "                            ls.append(df)\n",
    "\n",
    "all_data = pd.concat(ls, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For xi=0 and eta=0, the maximum reward is: 55655867.97208577\n",
      "And these are the meta-parameters that achieve it:\n",
      "Observe that radius == 0 implies that the solution follows the initial uhat\n",
      "    radius  factor  num_iterations        reward         time  delta   xi  \\\n",
      "3     0.05     1.0       20.000000  5.565587e+07  1385.065299    0.5  0.0   \n",
      "4     0.05     1.5       30.000000  5.565587e+07  1395.110099    0.5  0.0   \n",
      "5     0.05     2.0       40.000000  5.565587e+07  1408.321419    0.5  0.0   \n",
      "6     0.10     1.0       10.000000  5.565587e+07  1170.008036    0.5  0.0   \n",
      "7     0.10     2.0       20.000000  5.565587e+07  1187.123408    0.5  0.0   \n",
      "8     0.10     1.5       15.000000  5.565587e+07  1190.768425    0.5  0.0   \n",
      "9     0.20     1.0        5.000000  5.565587e+07  1060.251859    0.5  0.0   \n",
      "10    0.20     2.0       10.000000  5.565587e+07  1089.156359    0.5  0.0   \n",
      "11    0.20     1.5        7.500000  5.565587e+07  1089.570733    0.5  0.0   \n",
      "12    0.60     1.0        1.666667  5.565587e+07  1008.403764    0.5  0.0   \n",
      "13    0.40     1.5        3.750000  5.565587e+07  1059.038552    0.5  0.0   \n",
      "14    0.40     1.0        2.500000  5.565587e+07  1059.900424    0.5  0.0   \n",
      "15    0.40     2.0        5.000000  5.565587e+07  1062.032759    0.5  0.0   \n",
      "16    0.60     1.5        2.500000  5.565587e+07  1037.748655    0.5  0.0   \n",
      "17    0.60     2.0        3.333333  5.565587e+07  1037.984002    0.5  0.0   \n",
      "21    0.05     1.0       20.000000  5.565587e+07  1367.011287    0.5  0.0   \n",
      "22    0.05     1.5       30.000000  5.565587e+07  1386.272358    0.5  0.0   \n",
      "23    0.10     1.0       10.000000  5.565587e+07  1155.060515    0.5  0.0   \n",
      "24    0.10     2.0       20.000000  5.565587e+07  1175.512956    0.5  0.0   \n",
      "25    0.10     1.5       15.000000  5.565587e+07  1176.383500    0.5  0.0   \n",
      "26    0.05     2.0       40.000000  5.565587e+07  1387.911375    0.5  0.0   \n",
      "27    0.20     1.0        5.000000  5.565587e+07  1051.146842    0.5  0.0   \n",
      "28    0.20     1.5        7.500000  5.565587e+07  1078.867536    0.5  0.0   \n",
      "29    0.20     2.0       10.000000  5.565587e+07  1084.145708    0.5  0.0   \n",
      "30    0.40     1.0        2.500000  5.565587e+07  1012.025485    0.5  0.0   \n",
      "31    0.40     2.0        5.000000  5.565587e+07  1032.629370    0.5  0.0   \n",
      "32    0.40     1.5        3.750000  5.565587e+07  1040.862327    0.5  0.0   \n",
      "33    0.60     1.0        1.666667  5.565587e+07   994.483213    0.5  0.0   \n",
      "34    0.60     1.5        2.500000  5.565587e+07  1001.803814    0.5  0.0   \n",
      "35    0.60     2.0        3.333333  5.565587e+07  1006.995253    0.5  0.0   \n",
      "39    0.05     1.5       30.000000  5.565587e+07  1442.600630    0.5  0.0   \n",
      "40    0.05     1.0       20.000000  5.565587e+07  1445.325859    0.5  0.0   \n",
      "42    0.10     1.5       15.000000  5.565587e+07  1209.109498    0.5  0.0   \n",
      "43    0.05     2.0       40.000000  5.565587e+07  1452.852831    0.5  0.0   \n",
      "45    0.20     1.5        7.500000  5.565587e+07  1090.590838    0.5  0.0   \n",
      "46    0.20     2.0       10.000000  5.565587e+07  1092.547628    0.5  0.0   \n",
      "47    0.10     2.0       20.000000  5.565587e+07  1209.730609    0.5  0.0   \n",
      "48    0.40     1.5        3.750000  5.565587e+07  1055.496636    0.5  0.0   \n",
      "49    0.40     1.0        2.500000  5.565587e+07  1061.504666    0.5  0.0   \n",
      "50    0.40     2.0        5.000000  5.565587e+07  1065.647615    0.5  0.0   \n",
      "52    0.60     2.0        3.333333  5.565587e+07  1034.568227    0.5  0.0   \n",
      "53    0.60     1.5        2.500000  5.565587e+07  1037.953965    0.5  0.0   \n",
      "\n",
      "    icus  tests  freq  eta      initial_uhat  \n",
      "3   3000      0    14  0.0  dynamic_gradient  \n",
      "4   3000      0    14  0.0  dynamic_gradient  \n",
      "5   3000      0    14  0.0  dynamic_gradient  \n",
      "6   3000      0    14  0.0  dynamic_gradient  \n",
      "7   3000      0    14  0.0  dynamic_gradient  \n",
      "8   3000      0    14  0.0  dynamic_gradient  \n",
      "9   3000      0    14  0.0  dynamic_gradient  \n",
      "10  3000      0    14  0.0  dynamic_gradient  \n",
      "11  3000      0    14  0.0  dynamic_gradient  \n",
      "12  3000      0    14  0.0  dynamic_gradient  \n",
      "13  3000      0    14  0.0  dynamic_gradient  \n",
      "14  3000      0    14  0.0  dynamic_gradient  \n",
      "15  3000      0    14  0.0  dynamic_gradient  \n",
      "16  3000      0    14  0.0  dynamic_gradient  \n",
      "17  3000      0    14  0.0  dynamic_gradient  \n",
      "21  3000      0    14  0.0     full_lockdown  \n",
      "22  3000      0    14  0.0     full_lockdown  \n",
      "23  3000      0    14  0.0     full_lockdown  \n",
      "24  3000      0    14  0.0     full_lockdown  \n",
      "25  3000      0    14  0.0     full_lockdown  \n",
      "26  3000      0    14  0.0     full_lockdown  \n",
      "27  3000      0    14  0.0     full_lockdown  \n",
      "28  3000      0    14  0.0     full_lockdown  \n",
      "29  3000      0    14  0.0     full_lockdown  \n",
      "30  3000      0    14  0.0     full_lockdown  \n",
      "31  3000      0    14  0.0     full_lockdown  \n",
      "32  3000      0    14  0.0     full_lockdown  \n",
      "33  3000      0    14  0.0     full_lockdown  \n",
      "34  3000      0    14  0.0     full_lockdown  \n",
      "35  3000      0    14  0.0     full_lockdown  \n",
      "39  3000      0    14  0.0         full_open  \n",
      "40  3000      0    14  0.0         full_open  \n",
      "42  3000      0    14  0.0         full_open  \n",
      "43  3000      0    14  0.0         full_open  \n",
      "45  3000      0    14  0.0         full_open  \n",
      "46  3000      0    14  0.0         full_open  \n",
      "47  3000      0    14  0.0         full_open  \n",
      "48  3000      0    14  0.0         full_open  \n",
      "49  3000      0    14  0.0         full_open  \n",
      "50  3000      0    14  0.0         full_open  \n",
      "52  3000      0    14  0.0         full_open  \n",
      "53  3000      0    14  0.0         full_open  \n",
      "\n",
      "For xi=0 and eta=0.1, the maximum reward is: 51830839.42558997\n",
      "And these are the meta-parameters that achieve it:\n",
      "Observe that radius == 0 implies that the solution follows the initial uhat\n",
      "    radius  factor  num_iterations        reward         time  delta   xi  \\\n",
      "82     0.6     1.0        1.666667  5.183084e+07  1778.019186    0.5  0.0   \n",
      "83     0.6     1.5        2.500000  5.183084e+07  2446.093744    0.5  0.0   \n",
      "\n",
      "    icus  tests  freq  eta   initial_uhat  \n",
      "82  3000      0    14  0.1  full_lockdown  \n",
      "83  3000      0    14  0.1  full_lockdown  \n",
      "\n",
      "For xi=1115970.9 and eta=0, the maximum reward is: 44506331.4118062\n",
      "And these are the meta-parameters that achieve it:\n",
      "Observe that radius == 0 implies that the solution follows the initial uhat\n",
      "     radius  factor  num_iterations        reward         time  delta  \\\n",
      "106    0.05     1.0            20.0  4.450633e+07  1908.680885    0.5   \n",
      "107    0.05     2.0            40.0  4.450633e+07  1951.743587    0.5   \n",
      "108    0.05     1.5            30.0  4.450633e+07  1959.251306    0.5   \n",
      "\n",
      "            xi  icus  tests  freq  eta      initial_uhat  \n",
      "106  1115970.9  3000      0    14  0.0  dynamic_gradient  \n",
      "107  1115970.9  3000      0    14  0.0  dynamic_gradient  \n",
      "108  1115970.9  3000      0    14  0.0  dynamic_gradient  \n",
      "\n",
      "For xi=1115970.9 and eta=0.1, the maximum reward is: 40713653.45476649\n",
      "And these are the meta-parameters that achieve it:\n",
      "Observe that radius == 0 implies that the solution follows the initial uhat\n",
      "     radius  factor  num_iterations        reward         time  delta  \\\n",
      "167     0.2     1.5             7.5  4.071365e+07  5341.154602    0.5   \n",
      "170     0.2     2.0            10.0  4.071365e+07  5364.701872    0.5   \n",
      "\n",
      "            xi  icus  tests  freq  eta      initial_uhat  \n",
      "167  1115970.9  3000      0    14  0.1  dynamic_gradient  \n",
      "170  1115970.9  3000      0    14  0.1  dynamic_gradient  \n",
      "\n",
      "For xi=5207864.2 and eta=0, the maximum reward is: 15561841.509616494\n",
      "And these are the meta-parameters that achieve it:\n",
      "Observe that radius == 0 implies that the solution follows the initial uhat\n",
      "     radius  factor  num_iterations        reward         time  delta  \\\n",
      "214    0.05     1.0            20.0  1.556184e+07  2161.790505    0.5   \n",
      "217    0.05     1.5            30.0  1.556184e+07  2412.582879    0.5   \n",
      "218    0.05     2.0            40.0  1.556184e+07  2422.342513    0.5   \n",
      "\n",
      "            xi  icus  tests  freq  eta      initial_uhat  \n",
      "214  5207864.2  3000      0    14  0.0  dynamic_gradient  \n",
      "217  5207864.2  3000      0    14  0.0  dynamic_gradient  \n",
      "218  5207864.2  3000      0    14  0.0  dynamic_gradient  \n",
      "\n",
      "For xi=5207864.2 and eta=0.1, the maximum reward is: 12224516.63755381\n",
      "And these are the meta-parameters that achieve it:\n",
      "Observe that radius == 0 implies that the solution follows the initial uhat\n",
      "     radius  factor  num_iterations        reward         time  delta  \\\n",
      "270     0.1     1.0            10.0  1.222452e+07  6394.835696    0.5   \n",
      "271     0.1     1.5            15.0  1.222452e+07  6629.763073    0.5   \n",
      "274     0.1     2.0            20.0  1.222452e+07  6637.949119    0.5   \n",
      "\n",
      "            xi  icus  tests  freq  eta      initial_uhat  \n",
      "270  5207864.2  3000      0    14  0.1  dynamic_gradient  \n",
      "271  5207864.2  3000      0    14  0.1  dynamic_gradient  \n",
      "274  5207864.2  3000      0    14  0.1  dynamic_gradient  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First, look for each combination of parameters what combination of meta-param achieves the best rewards\n",
    "\n",
    "for delta in parameters[\"delta_schooling\"]:\n",
    "    for xi in parameters[\"xi\"]:\n",
    "        for icus in parameters[\"icus\"]:\n",
    "            for tests in parameters[\"tests\"]:\n",
    "                for freq in parameters[\"frequencies\"]:\n",
    "                    for eta in parameters[\"eta\"]:\n",
    "                        maximum_reward = all_data[(all_data.delta == delta) \n",
    "                                                 & (all_data.xi == xi) \n",
    "                                                 & (all_data.icus == icus)\n",
    "                                                 & (all_data.tests == tests) \n",
    "                                                 & (all_data.freq == freq[1])\n",
    "                                                 & (all_data.eta == eta)].reward.max()\n",
    "                        print(f\"For xi={xi} and eta={eta}, the maximum reward is: {maximum_reward}\")\n",
    "                        print(f\"And these are the meta-parameters that achieve it:\")\n",
    "                        print(\"Observe that radius == 0 implies that the solution follows the initial uhat\")\n",
    "                        print(all_data[all_data.reward == maximum_reward])\n",
    "                        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above that for any combination of parameters we achieve the maximum reward for some combination of meta_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll define the ratio of the rewards wrt to the maximum reward \n",
    "\n",
    "for delta in parameters[\"delta_schooling\"]:\n",
    "    for xi in parameters[\"xi\"]:\n",
    "        for icus in parameters[\"icus\"]:\n",
    "            for tests in parameters[\"tests\"]:\n",
    "                for freq in parameters[\"frequencies\"]:\n",
    "                    for eta in parameters[\"eta\"]:\n",
    "                        maximum_reward = all_data[(all_data.delta == delta) \n",
    "                                                 & (all_data.xi == xi) \n",
    "                                                 & (all_data.icus == icus)\n",
    "                                                 & (all_data.tests == tests) \n",
    "                                                 & (all_data.freq == freq[1])\n",
    "                                                 & (all_data.eta == eta)].reward.max()\n",
    "                        \n",
    "                        all_data.loc[(all_data.delta == delta)\n",
    "                                                 & (all_data.xi == xi) \n",
    "                                                 & (all_data.icus == icus)\n",
    "                                                 & (all_data.tests == tests) \n",
    "                                                 & (all_data.freq == freq[1])\n",
    "                                                 & (all_data.eta == eta), \"FractionalReward\"] = all_data[(all_data.delta == delta) \n",
    "                                                 & (all_data.xi == xi) \n",
    "                                                 & (all_data.icus == icus)\n",
    "                                                 & (all_data.tests == tests) \n",
    "                                                 & (all_data.freq == freq[1])\n",
    "                                                 & (all_data.eta == eta)].reward / maximum_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Meta Param: radius = 0, factor = 1, num iterations = 0\n",
      "Average Fractional Reward across starting points: -3.408234242719686\n",
      "Average time across starting points: 948.3297182718912\n",
      "-----------------------------------------------------\n",
      "Meta Param: radius = 0, factor = 1.5, num iterations = 0\n",
      "Average Fractional Reward across starting points: -3.408234242719686\n",
      "Average time across starting points: 950.0732090870539\n",
      "-----------------------------------------------------\n",
      "Meta Param: radius = 0, factor = 2, num iterations = 0\n",
      "Average Fractional Reward across starting points: -3.408234242719686\n",
      "Average time across starting points: 949.4243554936515\n",
      "-----------------------------------------------------\n",
      "Meta Param: radius = 0.05, factor = 1, num iterations = 20.0\n",
      "Average Fractional Reward across starting points: 0.9903751516101733\n",
      "Average time across starting points: 3466.9894530110887\n",
      "-----------------------------------------------------\n",
      "Meta Param: radius = 0.05, factor = 1.5, num iterations = 30.0\n",
      "Average Fractional Reward across starting points: 0.9919025683881476\n",
      "Average time across starting points: 3665.3172486358217\n",
      "-----------------------------------------------------\n",
      "Meta Param: radius = 0.05, factor = 2, num iterations = 40.0\n",
      "Average Fractional Reward across starting points: 0.9919983802774941\n",
      "Average time across starting points: 3938.9262190659842\n",
      "-----------------------------------------------------\n",
      "Meta Param: radius = 0.1, factor = 1, num iterations = 10.0\n",
      "Average Fractional Reward across starting points: 0.9892653775154887\n",
      "Average time across starting points: 3114.929850578308\n",
      "-----------------------------------------------------\n",
      "Meta Param: radius = 0.1, factor = 1.5, num iterations = 15.0\n",
      "Average Fractional Reward across starting points: 0.9896580142004324\n",
      "Average time across starting points: 3352.377712037828\n",
      "-----------------------------------------------------\n",
      "Meta Param: radius = 0.1, factor = 2, num iterations = 20.0\n",
      "Average Fractional Reward across starting points: 0.9862917517671251\n",
      "Average time across starting points: 3329.3932944403755\n",
      "-----------------------------------------------------\n",
      "Meta Param: radius = 0.2, factor = 1, num iterations = 5.0\n",
      "Average Fractional Reward across starting points: 0.9763817067007364\n",
      "Average time across starting points: 2921.421116997214\n",
      "-----------------------------------------------------\n",
      "Meta Param: radius = 0.2, factor = 1.5, num iterations = 7.5\n",
      "Average Fractional Reward across starting points: 0.9820705604068125\n",
      "Average time across starting points: 3552.5585776418447\n",
      "-----------------------------------------------------\n",
      "Meta Param: radius = 0.2, factor = 2, num iterations = 10.0\n",
      "Average Fractional Reward across starting points: 0.991798388716734\n",
      "Average time across starting points: 3615.169813569387\n",
      "-----------------------------------------------------\n",
      "Meta Param: radius = 0.4, factor = 1, num iterations = 2.5\n",
      "Average Fractional Reward across starting points: 0.9633739807772409\n",
      "Average time across starting points: 2030.1068807972802\n",
      "-----------------------------------------------------\n",
      "Meta Param: radius = 0.4, factor = 1.5, num iterations = 3.75\n",
      "Average Fractional Reward across starting points: 0.9671008454492424\n",
      "Average time across starting points: 2392.302131003804\n",
      "-----------------------------------------------------\n",
      "Meta Param: radius = 0.4, factor = 2, num iterations = 5.0\n",
      "Average Fractional Reward across starting points: 0.9722040107015656\n",
      "Average time across starting points: 2662.0993874493765\n",
      "-----------------------------------------------------\n",
      "Meta Param: radius = 0.6, factor = 1, num iterations = 1.6666666666666667\n",
      "Average Fractional Reward across starting points: 0.8147019165602579\n",
      "Average time across starting points: 1630.7088381846745\n",
      "-----------------------------------------------------\n",
      "Meta Param: radius = 0.6, factor = 1.5, num iterations = 2.5\n",
      "Average Fractional Reward across starting points: 0.8599192385793504\n",
      "Average time across starting points: 2128.563480403688\n",
      "-----------------------------------------------------\n",
      "Meta Param: radius = 0.6, factor = 2, num iterations = 3.3333333333333335\n",
      "Average Fractional Reward across starting points: 0.8616599146341983\n",
      "Average time across starting points: 2482.2778435283235\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa1fc6c9f60>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now for each combination of meta-parameters we can plot a histogram of the fractional rewards.\n",
    "# This should give an idea of how good the meta-parameters are for all the instances.\n",
    "\n",
    "\n",
    "# Here you can choose which combination of meta-param to plot\n",
    "meta_parameters = {\n",
    "        \"trust_region_radius\":[0,0.05,0.1,0.2,0.4,0.6],\n",
    "        \"max_inner_iterations_mult\":[1, 1.5, 2],\n",
    "        \"initial_uhat\":[\"dynamic_gradient\", \"full_lockdown\", \"full_open\"]\n",
    "    }\n",
    "\n",
    "\n",
    "#You can choose which combination of parameters to plot\n",
    "xis = [0, 30 * 37199.03, 140 * 37199.03]\n",
    "# , 140 * 37199.03]\n",
    "etas = [0,0.1]\n",
    "\n",
    "\n",
    "times = []\n",
    "frac_rewards = []\n",
    "param = []\n",
    "\n",
    "for radius in meta_parameters[\"trust_region_radius\"]:\n",
    "    for factor in meta_parameters[\"max_inner_iterations_mult\"]:\n",
    "        \n",
    "        frac_reward_list_rad_fact = []\n",
    "        running_times = []\n",
    "        for initial_uhat in meta_parameters[\"initial_uhat\"]:\n",
    "#             print(f\"Meta Param: radius = {radius}, factor = {factor}, num iterations = {factor/radius if radius>0 else 0}, initia uhat = {initial_uhat}\")\n",
    "            frac_rewards_list = list(all_data.loc[(all_data.radius==radius) &\n",
    "                                                  (all_data.factor==factor) & \n",
    "                                                  (all_data.initial_uhat==initial_uhat) &\n",
    "                                                  (all_data.xi.isin(xis)) &\n",
    "                                                  (all_data.eta.isin(etas)), \"FractionalReward\"])\n",
    "            partial_running_times = list(all_data.loc[(all_data.radius==radius) &\n",
    "                                                  (all_data.factor==factor) & \n",
    "                                                  (all_data.initial_uhat==initial_uhat) &\n",
    "                                                  (all_data.xi.isin(xis)) &\n",
    "                                                  (all_data.eta.isin(etas)), \"time\"])\n",
    "#             print(f\"List of Fractional Rewards: {frac_rewards_list}\")\n",
    "            frac_reward_list_rad_fact += frac_rewards_list\n",
    "            running_times += partial_running_times\n",
    "#             print(f\"Average Fractional Reward: {np.mean(frac_rewards_list)}\")\n",
    "            num_bins = 128\n",
    "#             print(\"Histogram of Fractional Rewards:\")\n",
    "#             plt.hist(frac_rewards_list, num_bins, facecolor='blue', alpha=0.5)\n",
    "#             plt.show()\n",
    "        print(\"-----------------------------------------------------\")\n",
    "        print(f\"Meta Param: radius = {radius}, factor = {factor}, num iterations = {factor/radius if radius>0 else 0}\")\n",
    "        print(f\"Average Fractional Reward across starting points: {np.mean(frac_reward_list_rad_fact)}\")\n",
    "        print(f\"Average time across starting points: {np.mean(running_times)}\")\n",
    "        times.append(np.mean(running_times))\n",
    "        frac_rewards.append(np.mean(frac_reward_list_rad_fact))\n",
    "        param.append((radius, factor))\n",
    "\n",
    "# plt.scatter(times[3:], frac_rewards[3:])\n",
    "# plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(times[3:], frac_rewards[3:])\n",
    "\n",
    "for i, txt in enumerate(param[3:]):\n",
    "    ax.annotate(txt, (times[i], frac_rewards[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
