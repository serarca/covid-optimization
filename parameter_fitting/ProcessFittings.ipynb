{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "mypath = \"./fittings_switch_100/\"\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "for folder in onlyfiles:\n",
    "    if 'fit' in folder:\n",
    "        with open(mypath+folder) as file:\n",
    "            r = yaml.load(file, Loader=yaml.UnsafeLoader)\n",
    "            r['replicating_v'] = [r['days_ahead']]+r['result']+[r['days_switch']]\n",
    "            all_results.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value 0.6896883721593612 alpha: 0.38739075911496973 mix: 0.9670094172035613\n",
      "value 0.7034994478200238 alpha: 0.42141712161576 mix: 0.3712984664748155\n",
      "value 0.7045210687301932 alpha: 0.4568921257721544 mix: 9.284176363718078e-05\n"
     ]
    }
   ],
   "source": [
    "best = []\n",
    "for r in all_results:\n",
    "    if r['value']<0.71:\n",
    "        best.append(r)\n",
    "        print(\"value\",r['value'],\"alpha:\",r['result'][0],\"mix:\",r['result'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_ahead 76\n",
      "days_switch 30\n",
      "alpha: 0.38739075911496973\n",
      "beta_change: -0.40073206230324354\n",
      "mix: 0.9670094172035613\n",
      "school_lockdown: 0.0\n",
      "school_may_jun: 0.0\n",
      "school_jul_aug: 0.2\n",
      "school_sep_oct: 1.0\n",
      "change_p_ICU: 0.6649637320414583\n",
      "change_lambda_H: -0.5\n",
      "change_lambda_ICU: 1.0\n",
      "change_p_death: 0.13102711057496497\n"
     ]
    }
   ],
   "source": [
    "# In[57]:\n",
    "b = best[0]\n",
    "days_ahead_opt = b['days_ahead']\n",
    "days_switch_opt = b['days_switch']\n",
    "v= b['result']\n",
    "print(\"days_ahead\",days_ahead_opt)\n",
    "print(\"days_switch\",days_switch_opt)\n",
    "n_samples = 1\n",
    "maxiter = 50\n",
    "print(\"alpha:\",v[0])\n",
    "print(\"beta_change:\",v[1]-1)\n",
    "print(\"mix:\",v[2])\n",
    "print(\"school_lockdown:\",v[3])\n",
    "print(\"school_may_jun:\",v[4])\n",
    "print(\"school_jul_aug:\",v[5])\n",
    "print(\"school_sep_oct:\",v[6])\n",
    "print(\"change_p_ICU:\",v[7]-1)\n",
    "print(\"change_lambda_H:\",v[8]-1)\n",
    "print(\"change_lambda_ICU:\",v[9]-1)\n",
    "print(\"change_p_death:\",v[10]-1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'groups': 'all', 'params_to_try': {'delta_schooling': [0.5, 1, 5], 'xi': [0, 371990.3, 929975.75, 1859951.5, 3719903, 5579854.5], 'icus': [2000, 2300, 2600, 2900, 3200], 'tests': [[0, 0], [30000, 30000], [60000, 60000], [120000, 120000]], 'testing': ['homogeneous'], 'eta': [0, 0.1, 0.2]}}\n",
      "{'groups': 'all', 'params_to_try': {'delta_schooling': [0.5, 1, 5], 'xi': [0, 371990.3, 929975.75, 1859951.5, 3719903, 5579854.5], 'icus': [2000, 2300, 2600, 2900, 3200], 'tests': [[0, 0], [30000, 30000], [60000, 60000], [120000, 120000]], 'testing': ['homogeneous'], 'eta': [0, 0.1, 0.2]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergioacamelogomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:110: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/sergioacamelogomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:118: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/sergioacamelogomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:120: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/sergioacamelogomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:121: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/sergioacamelogomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:125: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/sergioacamelogomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:127: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/sergioacamelogomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:128: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/sergioacamelogomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:132: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/sergioacamelogomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:134: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/sergioacamelogomez/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:135: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_samples = 100\n",
    "maxiter = 100\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import yaml\n",
    "from inspect import getsourcefile\n",
    "import os.path\n",
    "import sys\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "current_path = os.path.abspath(getsourcefile(lambda:0))\n",
    "current_dir = os.path.dirname(current_path)\n",
    "parentdir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0,parentdir) \n",
    "sys.path.insert(0, parentdir+\"/heuristics\")\n",
    "sys.path.insert(0, parentdir+\"/heuristics/LP-Models\")\n",
    "sys.path.insert(0, parentdir+\"/fast_gradient\")\n",
    "\n",
    "\n",
    "from fast_group import FastDynamicalModel\n",
    "from aux import *\n",
    "\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import math\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "age_groups = ['age_group_0_9', 'age_group_10_19', 'age_group_20_29','age_group_30_39', 'age_group_40_49', 'age_group_50_59', 'age_group_60_69', 'age_group_70_79', 'age_group_80_plus']\n",
    "old_age_groups = ['age_group_50_59', 'age_group_60_69', 'age_group_70_79', 'age_group_80_plus']\n",
    "econ_activities = ['transport', 'leisure', 'other']\n",
    "cont = [ 'S', 'E', 'I', 'R', 'N', 'Ia', 'Ips',            'Ims', 'Iss', 'Rq', 'H', 'ICU', 'D' ]\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"donnees-hospitalieres-classe-age-covid19-2020-10-28-19h00.csv\", sep=\";\")\n",
    "data.head()\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# Load the data\n",
    "google = pd.read_csv(\"2020_FR_Region_Mobility_Report.csv\")\n",
    "google = google[google['sub_region_1']==\"ÃŽle-de-France\"]\n",
    "google = google[pd.isnull(google['sub_region_2'])]\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "# Apply an smoothing to the data\n",
    "initial_work = ((google[\"workplaces_percent_change_from_baseline\"]+100)/100).values\n",
    "google_days = [datetime.strptime(google[\"date\"].values[i], '%Y-%m-%d').weekday() for i in range(len(google[\"date\"]))]\n",
    "new_work = []\n",
    "for i in range(len(initial_work)):\n",
    "    if google_days[i]<=4:\n",
    "        new_work.append(initial_work[i])\n",
    "    elif google_days[i]==5:\n",
    "        numbers_for_mean = []\n",
    "        for k in range(i-5,i):\n",
    "            if k>=0 and k<len(initial_work):\n",
    "                numbers_for_mean.append(initial_work[k])\n",
    "        for k in range(i+2,i+7):\n",
    "            if k>=0 and k<len(initial_work):\n",
    "                numbers_for_mean.append(initial_work[k])\n",
    "        new_work.append(np.mean(numbers_for_mean))\n",
    "    elif google_days[i]==6:\n",
    "        numbers_for_mean = []\n",
    "        for k in range(i-6,i-1):\n",
    "            if k>=0 and k<len(initial_work):\n",
    "                numbers_for_mean.append(initial_work[k])\n",
    "        for k in range(i+1,i+6):\n",
    "            if k>=0 and k<len(initial_work):\n",
    "                numbers_for_mean.append(initial_work[k])\n",
    "        new_work.append(np.mean(numbers_for_mean))\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "# Assign data\n",
    "google['work'] = new_work\n",
    "google['transport'] = (google[\"transit_stations_percent_change_from_baseline\"]+100)/100\n",
    "google['other'] = 0.33*(google[\"retail_and_recreation_percent_change_from_baseline\"]+100)/100+0.67*(google[\"grocery_and_pharmacy_percent_change_from_baseline\"]+100)/100\n",
    "google['leisure'] = 0.33*(google[\"parks_percent_change_from_baseline\"]+100)/100+0.67*(google[\"retail_and_recreation_percent_change_from_baseline\"]+100)/100\n",
    "google = google.reset_index()\n",
    "google.to_csv('smoothed.csv')\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "# Extract days \n",
    "data = data[data['jour']<='2020-10-21']\n",
    "french_days = data[data['reg']==11][data['cl_age90']==0].jour.values\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "# Extract data from french dataset\n",
    "deaths_real = {\n",
    "    age_groups[i]:data[data['reg']==11][data['cl_age90']==10*i+9].dc.values for i in range(0,9)\n",
    "}\n",
    "deaths_real['age_group_80_plus']+=data[data['reg']==11][data['cl_age90']==90].dc.values\n",
    "deaths_real['total']=data[data['reg']==11][data['cl_age90']==0].dc.values\n",
    "\n",
    "\n",
    "icus_real = {\n",
    "    age_groups[i]:data[data['reg']==11][data['cl_age90']==10*i+9].rea.values for i in range(0,9)\n",
    "}\n",
    "icus_real['age_group_80_plus']+=data[data['reg']==11][data['cl_age90']==90].rea.values\n",
    "icus_real['total']=data[data['reg']==11][data['cl_age90']==0].rea.values\n",
    "\n",
    "\n",
    "beds_real = {\n",
    "    age_groups[i]:data[data['reg']==11][data['cl_age90']==10*i+9].hosp.values-data[data['reg']==11][data['cl_age90']==10*i+9].rea.values for i in range(0,9)\n",
    "}\n",
    "beds_real['age_group_80_plus']+=data[data['reg']==11][data['cl_age90']==90].hosp.values - data[data['reg']==11][data['cl_age90']==90].rea.values\n",
    "beds_real['total']=data[data['reg']==11][data['cl_age90']==0].hosp.values - data[data['reg']==11][data['cl_age90']==0].rea.values\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "# Load the original SEIR parameters\n",
    "params = pd.read_excel(\"./ile-de-france_data_master.xlsx\",sheet_name=\"SEIR_params\", index_col = 0)\n",
    "initial_params = {\n",
    "    \"mu\":params['mu'].values,\n",
    "    \"sigma\":params['sigma'].values,\n",
    "    \"p_ICU\":params['p_ICU'].values,\n",
    "    \"p_H\":params['p_H'].values,\n",
    "    \"lambda_H_R\":params['lambda_HR'].values,\n",
    "    \"lambda_H_D\":params['lambda_HD'].values,\n",
    "    \"lambda_ICU_R\":params['lambda_ICUR'].values,\n",
    "    \"lambda_ICU_D\":params['lambda_ICUD'].values,\n",
    "    \"lambda_ICU\":params['lambda_ICU'].values,\n",
    "    \"lambda_H\":params['lambda_H'].values,\n",
    "    \"p_death\":params['p_death_cond_ss'].values,\n",
    "    \"p_recov\":params['p_recov_cond_ss'].values,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "# Smooth the french data\n",
    "start_smooth = datetime.strptime(\"2020-09-01\", '%Y-%m-%d')\n",
    "end_smooth = datetime.strptime(\"2020-10-01\", '%Y-%m-%d')\n",
    "for ag in beds_real:\n",
    "    new_series = []\n",
    "    for i in range(len(beds_real[ag])):\n",
    "        day = datetime.strptime(french_days[i], '%Y-%m-%d')\n",
    "        lower = (day-start_smooth).days\n",
    "        upper = (end_smooth-day).days\n",
    "        if lower>=0 and upper>=0:\n",
    "            n_days_before = min(lower,7)\n",
    "            n_days_after = min(upper,7)\n",
    "            avg_value = np.mean(beds_real[ag][(i-n_days_before):(i+1+n_days_after)])\n",
    "            new_series.append(avg_value)\n",
    "        else:\n",
    "            new_series.append(beds_real[ag][i])\n",
    "    beds_real[ag] = np.array(new_series)\n",
    "        \n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([datetime.strptime(d, '%Y-%m-%d') for d in french_days],beds_real[\"total\"])\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "region = \"Ile-de-France\"\n",
    "\n",
    "# Read group parameters\n",
    "with open(\"../parameters/\"+region+\".yaml\") as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    universe_params = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    \n",
    "# Read initialization\n",
    "with open(\"../initialization/patient_zero.yaml\") as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    original_initialization = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "# Read econ parameters\n",
    "with open(\"../parameters/econ.yaml\") as file:\n",
    "    econ_params = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "experiment_params = {\n",
    "    'delta_schooling':0.5,\n",
    "    'xi':0,\n",
    "    'icus':4000,\n",
    "}\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "# Create relevant dates\n",
    "date_1 = datetime.strptime(\"2020-03-17\", '%Y-%m-%d')\n",
    "date_2 = datetime.strptime(\"2020-05-11\", '%Y-%m-%d')\n",
    "date_3 = datetime.strptime(\"2020-07-01\", '%Y-%m-%d')\n",
    "date_4 = datetime.strptime(\"2020-09-01\", '%Y-%m-%d')\n",
    "final_date = datetime.strptime(\"2020-10-21\", '%Y-%m-%d')\n",
    "\n",
    "rates_date = datetime.strptime(\"2020-03-01\", '%Y-%m-%d')\n",
    "\n",
    "first_day_google = datetime.strptime(\"2020-02-15\", '%Y-%m-%d')\n",
    "days_between_google = (date_1-first_day_google).days\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "# Fill up the original parameters\n",
    "original_beta = universe_params['seir-groups'][\"age_group_0_9\"][\"parameters\"][\"beta\"]\n",
    "t_days_beta = 730\n",
    "\n",
    "for ag in universe_params['seir-groups']:\n",
    "    universe_params['seir-groups'][ag][\"parameters\"][\"beta\"] = (\n",
    "        [original_beta for t in range(t_days_beta) ]\n",
    "    )\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "# Create model\n",
    "mixing_method = {}\n",
    "dynModel = FastDynamicalModel(universe_params, econ_params, experiment_params, 1, mixing_method, 1e9, 0, 0)\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "# Generate samples\n",
    "np.random.seed(0)\n",
    "samples = 1+np.random.randn(n_samples,(final_date-date_1).days+150, 5)*0.05/2/np.sqrt(3)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "best_v = 0\n",
    "best_error = float('inf')\n",
    "validation_date = datetime.strptime(\"2020-10-21\", '%Y-%m-%d')\n",
    "# This is the smoothening\n",
    "trans_days = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a nominal path\n",
    "samples = samples*0+1\n",
    "n_sample = 0\n",
    "\n",
    "# Choose the best parameters\n",
    "best_error_i = np.argmin([r['value'] for r in all_results])\n",
    "best_v = all_results[best_error_i][\"result\"]\n",
    "best_days_ahead = all_results[best_error_i][\"days_ahead\"]\n",
    "best_days_switch = all_results[best_error_i][\"days_switch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_ahead = best_days_ahead\n",
    "alpha_mixing = best_v[0]\n",
    "\n",
    "beta_normal = original_beta\n",
    "beta_masks = beta_normal*best_v[1]\n",
    "\n",
    "mix_1 = best_v[2]\n",
    "mix_2 = 0\n",
    "\n",
    "alphas_d = {\n",
    "    'work':alpha_mixing,\n",
    "    'transport':alpha_mixing,\n",
    "    'school':alpha_mixing,\n",
    "    'other':alpha_mixing,\n",
    "    'leisure':alpha_mixing,\n",
    "    'home':alpha_mixing,\n",
    "}\n",
    "\n",
    "# School lockdowns\n",
    "school_lockdown = best_v[3]\n",
    "school_may_jun = best_v[4]\n",
    "school_jul_aug = best_v[5]\n",
    "school_sep_oct = best_v[6]\n",
    "\n",
    "# Changes to SEIR rates\n",
    "fraction_p_ICU = best_v[7]\n",
    "change_lambda_H_aft = best_v[8]\n",
    "change_lambda_ICU_aft = best_v[9]\n",
    "change_p_death_aft = best_v[10]\n",
    "\n",
    "# Date that a change occurs\n",
    "days_change_rates = best_days_switch\n",
    "\n",
    "\n",
    "google['other'] = mix_1*(google[\"retail_and_recreation_percent_change_from_baseline\"]+100)/100+(1-mix_1)*(google[\"grocery_and_pharmacy_percent_change_from_baseline\"]+100)/100\n",
    "google['leisure'] = mix_2*(google[\"parks_percent_change_from_baseline\"]+100)/100+(1-mix_2)*(google[\"retail_and_recreation_percent_change_from_baseline\"]+100)/100\n",
    "\n",
    "\n",
    "# Number of days\n",
    "days_before_date_1 = int(days_ahead)\n",
    "days_between_dates_1_2 = (date_2-date_1).days\n",
    "days_between_dates_2_3 = (date_3-date_2).days\n",
    "days_between_dates_3_4 = (date_4-date_3).days\n",
    "days_after_date_4 = (final_date-date_4).days\n",
    "total_days = days_before_date_1 + days_between_dates_1_2 + days_between_dates_2_3 + days_between_dates_3_4 + days_after_date_4\n",
    "validation_days = days_before_date_1 + (final_date-date_1).days\n",
    "\n",
    "# Some additional calculations\n",
    "days_rates_start = (rates_date - date_1).days + days_ahead\n",
    "\n",
    "# Construct initialization\n",
    "initialization = deepcopy(original_initialization)\n",
    "for i,group in enumerate(age_groups):\n",
    "    if group == \"age_group_40_49\":\n",
    "        initialization[group][\"I\"] = initialization[group][\"I\"] + 1\n",
    "        initialization[group][\"S\"] = initialization[group][\"S\"] - 1\n",
    "    initialization[group][\"N\"] = initialization[group][\"S\"] + initialization[group][\"E\"] + initialization[group][\"I\"] + initialization[group][\"R\"]\n",
    "\n",
    "\n",
    "# Alphas\n",
    "a_before_google = {\n",
    "    'home':1.0,\n",
    "    'leisure':1.0,\n",
    "    'other':1.0,\n",
    "    'school':1.0,\n",
    "    'transport':1.0,\n",
    "    'work':1.0\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Calculate alphas\n",
    "alphas_vec = []\n",
    "for t in range(days_before_date_1-days_between_google):\n",
    "    alphas = {}\n",
    "    for age_group in age_groups:\n",
    "        alphas[age_group] = a_before_google\n",
    "    alphas_vec.append(alphas)\n",
    "\n",
    "counter = 0\n",
    "for t in range(days_between_google):\n",
    "    alphas = {}\n",
    "    for age_group in age_groups:\n",
    "        alphas[age_group] = {\n",
    "            'home':1.0,\n",
    "            'leisure':google['leisure'][counter]*samples[n_sample,counter,0],\n",
    "            'other':google['other'][counter]*samples[n_sample,counter,1],\n",
    "            'school':1.0,\n",
    "            'transport':google['transport'][counter]*samples[n_sample,counter,3],\n",
    "            'work':google['work'][counter]*samples[n_sample,counter,4],\n",
    "        }\n",
    "    alphas_vec.append(alphas)   \n",
    "    counter += 1\n",
    "\n",
    "for t in range(days_between_dates_1_2):\n",
    "    alphas = {}\n",
    "    for age_group in age_groups:\n",
    "        alphas[age_group] = {\n",
    "            'home':1.0,\n",
    "            'leisure':google['leisure'][counter]*samples[n_sample,counter,0],\n",
    "            'other':google['other'][counter]*samples[n_sample,counter,1],\n",
    "            'school':school_lockdown*samples[n_sample,counter,2],\n",
    "            'transport':google['transport'][counter]*samples[n_sample,counter,3],\n",
    "            'work':google['work'][counter]*samples[n_sample,counter,4],\n",
    "        }\n",
    "    alphas_vec.append(alphas)   \n",
    "    counter += 1\n",
    "\n",
    "for t in range(days_between_dates_2_3):\n",
    "    alphas = {}\n",
    "    for age_group in age_groups:\n",
    "        alphas[age_group] = {\n",
    "            'home':1.0,\n",
    "            'leisure':google['leisure'][counter]*samples[n_sample,counter,0],\n",
    "            'other':google['other'][counter]*samples[n_sample,counter,1],\n",
    "            'school':school_may_jun*samples[n_sample,counter,2],\n",
    "            'transport':google['transport'][counter]*samples[n_sample,counter,3],\n",
    "            'work':google['work'][counter]*samples[n_sample,counter,4],\n",
    "        }\n",
    "    alphas_vec.append(alphas)   \n",
    "    counter += 1\n",
    "\n",
    "for t in range(days_between_dates_3_4):\n",
    "    alphas = {}\n",
    "    for age_group in age_groups:\n",
    "        alphas[age_group] = {\n",
    "            'home':1.0,\n",
    "            'leisure':google['leisure'][counter]*samples[n_sample,counter,0],\n",
    "            'other':google['other'][counter]*samples[n_sample,counter,1],\n",
    "            'school':school_jul_aug*samples[n_sample,counter,2],\n",
    "            'transport':google['transport'][counter]*samples[n_sample,counter,3],\n",
    "            'work':google['work'][counter]*samples[n_sample,counter,4],\n",
    "        }\n",
    "    alphas_vec.append(alphas)   \n",
    "    counter += 1\n",
    "\n",
    "for t in range(days_after_date_4):\n",
    "    alphas = {}\n",
    "    for age_group in age_groups:\n",
    "        alphas[age_group] = {\n",
    "            'home':1.0,\n",
    "            'leisure':google['leisure'][counter]*samples[n_sample,counter,0],\n",
    "            'other':google['other'][counter]*samples[n_sample,counter,1],\n",
    "            'school':school_sep_oct*samples[n_sample,counter,2],\n",
    "            'transport':google['transport'][counter]*samples[n_sample,counter,3],\n",
    "            'work':google['work'][counter]*samples[n_sample,counter,4],\n",
    "        }\n",
    "    alphas_vec.append(alphas)\n",
    "    counter += 1\n",
    "\n",
    "# Calculate tests\n",
    "tests = np.zeros(len(age_groups))\n",
    "\n",
    "\n",
    "# Run model\n",
    "model_data_beds = {ag:[] for ag in age_groups+[\"total\"]}\n",
    "model_data_icus = {ag:[] for ag in age_groups+[\"total\"]}\n",
    "model_data_deaths = {ag:[] for ag in age_groups+[\"total\"]}\n",
    "\n",
    "state = state_to_matrix(initialization)\n",
    "t_beds = 0\n",
    "t_icus = 0\n",
    "t_deaths = 0\n",
    "for i,ag in enumerate(age_groups):\n",
    "    state_H = state[i,cont.index(\"H\")]\n",
    "    state_ICU = state[i,cont.index(\"ICU\")]\n",
    "    state_D = state[i,cont.index(\"D\")]\n",
    "    model_data_beds[ag].append(state_H)\n",
    "    model_data_icus[ag].append(state_ICU)\n",
    "    model_data_deaths[ag].append(state_D)\n",
    "    t_beds+= state_H\n",
    "    t_icus+= state_ICU\n",
    "    t_deaths+= state_D\n",
    "model_data_beds[\"total\"].append(t_beds)\n",
    "model_data_icus[\"total\"].append(t_icus)\n",
    "model_data_deaths[\"total\"].append(t_deaths)\n",
    "\n",
    "\n",
    "dynModel.beta = np.zeros((len(age_groups),len(dynModel.groups[age_groups[0]].parameters[\"beta\"])))\n",
    "for i in range(len(age_groups)):\n",
    "    for j in range(len(dynModel.groups[age_groups[0]].parameters[\"beta\"])):\n",
    "        if j < int(days_rates_start+days_change_rates):\n",
    "            dynModel.beta[i,j] = beta_normal\n",
    "        else:\n",
    "            d_after = j-int(days_rates_start+days_change_rates)\n",
    "            d_portion = max(trans_days-d_after,0)/trans_days\n",
    "            dynModel.beta[i,j] = beta_normal*d_portion+beta_masks*(1-d_portion)\n",
    "\n",
    "for t in range(total_days):\n",
    "    current_date = date_1+timedelta(days=t-days_before_date_1)\n",
    "    day_of_week = current_date.weekday()\n",
    "\n",
    "    update_contacts = True\n",
    "\n",
    "    if t<int(days_rates_start+days_change_rates):\n",
    "        dynModel.p_H = initial_params[\"p_H\"]\n",
    "        dynModel.p_ICU = initial_params[\"p_ICU\"]\n",
    "\n",
    "        lambda_H = initial_params[\"lambda_H\"]\n",
    "        lambda_ICU = initial_params[\"lambda_ICU\"]\n",
    "        p_death = initial_params[\"p_death\"]\n",
    "\n",
    "        dynModel.lambda_H_D = p_death*lambda_H\n",
    "        dynModel.lambda_H_R = (1-p_death)*lambda_H\n",
    "        dynModel.lambda_ICU_D = p_death*lambda_ICU\n",
    "        dynModel.lambda_ICU_R = (1-p_death)*lambda_ICU\n",
    "\n",
    "    else:\n",
    "        d_after = t-int(days_rates_start+days_change_rates)\n",
    "        d_portion = max(trans_days-d_after,0)/trans_days\n",
    "\n",
    "        dynModel.p_ICU = initial_params[\"p_ICU\"]*d_portion+initial_params[\"p_ICU\"]*fraction_p_ICU*(1-d_portion)\n",
    "        dynModel.p_H = (initial_params[\"p_H\"]+initial_params[\"p_ICU\"])-(initial_params[\"p_ICU\"]*d_portion+initial_params[\"p_ICU\"]*fraction_p_ICU*(1-d_portion))\n",
    "\n",
    "        lambda_H = initial_params[\"lambda_H\"]*d_portion+initial_params[\"lambda_H\"]*change_lambda_H_aft*(1-d_portion)\n",
    "        lambda_ICU = initial_params[\"lambda_ICU\"]*d_portion+ initial_params[\"lambda_ICU\"]*change_lambda_ICU_aft*(1-d_portion)\n",
    "        p_death = initial_params[\"p_death\"]*d_portion+initial_params[\"p_death\"]*change_p_death_aft*(1-d_portion)\n",
    "\n",
    "        dynModel.lambda_H_D = p_death*lambda_H\n",
    "        dynModel.lambda_H_R = (1-p_death)*lambda_H\n",
    "        dynModel.lambda_ICU_D = p_death*lambda_ICU\n",
    "        dynModel.lambda_ICU_R = (1-p_death)*lambda_ICU\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    season = \"spc\"\n",
    "    dynModel.mixing_method = {\n",
    "            \"name\":\"mult\",\n",
    "            \"param_alpha\":alphas_d,\n",
    "            \"param_beta\":alphas_d,\n",
    "        }\n",
    "\n",
    "    state,_ = dynModel.take_time_step(state, tests, tests, alphas_to_matrix(alphas_vec[t]), t, season, update_contacts=update_contacts)\n",
    "    t_beds = 0\n",
    "    t_icus = 0\n",
    "    t_deaths = 0\n",
    "    for i,ag in enumerate(age_groups):\n",
    "        state_H = state[i,cont.index(\"H\")]\n",
    "        state_ICU = state[i,cont.index(\"ICU\")]\n",
    "        state_D = state[i,cont.index(\"D\")]\n",
    "        model_data_beds[ag].append(state_H)\n",
    "        model_data_icus[ag].append(state_ICU)\n",
    "        model_data_deaths[ag].append(state_D)\n",
    "        t_beds+= state_H\n",
    "        t_icus+= state_ICU\n",
    "        t_deaths+= state_D\n",
    "    #print(t_beds)\n",
    "    model_data_beds[\"total\"].append(t_beds)\n",
    "    model_data_icus[\"total\"].append(t_icus)\n",
    "    model_data_deaths[\"total\"].append(t_deaths)\n",
    "    \n",
    "final_state = state\n",
    "\n",
    "\n",
    "initial_date = date_1-timedelta(days=days_before_date_1)\n",
    "\n",
    "# Calculate the days of the model\n",
    "days_model = [initial_date+timedelta(days = t) for t in range(total_days + 1)]\n",
    "\n",
    "# Indices where to put the real data\n",
    "indices = [(datetime.strptime(d, '%Y-%m-%d') - initial_date).days for d in french_days]\n",
    "\n",
    "# Real data\n",
    "real_data_beds = {ag:[float('nan')]*len(days_model) for ag in age_groups+[\"total\"]}\n",
    "real_data_icus = {ag:[float('nan')]*len(days_model) for ag in age_groups+[\"total\"]}\n",
    "real_data_deaths = {ag:[float('nan')]*len(days_model) for ag in age_groups+[\"total\"]}\n",
    "\n",
    "for k,ind in enumerate(indices):\n",
    "    for ag in age_groups+[\"total\"]:\n",
    "        real_data_beds[ag][ind] = beds_real[ag][k] if beds_real[ag][k]!=0 else float('nan')\n",
    "        real_data_icus[ag][ind] = icus_real[ag][k] if icus_real[ag][k]!=0 else float('nan')\n",
    "        real_data_deaths[ag][ind] = deaths_real[ag][k] if deaths_real[ag][k]!=0 else float('nan')\n",
    "\n",
    "\n",
    "tail_constant = 0.5\n",
    "peak_constant = 0.25\n",
    "error_beds = 0\n",
    "error_icus = 0\n",
    "error_deaths = 0\n",
    "\n",
    "peak_beds = np.nanargmax(np.array(real_data_beds[\"total\"]))\n",
    "peak_icus = np.nanargmax(np.array(real_data_icus[\"total\"]))\n",
    "peak_deaths = peak_beds+30\n",
    "\n",
    "#         for ag in old_age_groups:\n",
    "#             error_beds += np.nanmean((np.abs(np.array(model_data_beds[ag])-np.array(real_data_beds[ag]))/np.array(real_data_beds[ag]))[0:validation_days-1])\n",
    "#             error_icus += np.nanmean((np.abs(np.array(model_data_icus[ag])-np.array(real_data_icus[ag]))/np.array(real_data_icus[ag]))[0:validation_days-1])\n",
    "#             error_deaths += np.nanmean((np.abs(np.array(model_data_deaths[ag])-np.array(real_data_deaths[ag]))/np.array(real_data_deaths[ag]))[0:validation_days-1])\n",
    "error_beds_total = np.nanmean((np.abs(np.array(model_data_beds[\"total\"])-np.array(real_data_beds[\"total\"]))/np.array(real_data_beds[\"total\"]))[0:validation_days-14])\n",
    "error_beds_tail = tail_constant*np.nanmean((np.abs(np.array(model_data_beds[\"total\"])-np.array(real_data_beds[\"total\"]))/np.array(real_data_beds[\"total\"]))[validation_days-14:validation_days])\n",
    "error_beds_peak = peak_constant*np.nanmean((np.abs(np.array(model_data_beds[\"total\"])-np.array(real_data_beds[\"total\"]))/np.array(real_data_beds[\"total\"]))[peak_beds:peak_beds+1])\n",
    "\n",
    "error_icus_total = 0.5*np.nanmean((np.abs(np.array(model_data_icus[\"total\"])-np.array(real_data_icus[\"total\"]))/np.array(real_data_icus[\"total\"]))[0:validation_days-14])\n",
    "error_icus_tail = 2*tail_constant*np.nanmean((np.abs(np.array(model_data_icus[\"total\"])-np.array(real_data_icus[\"total\"]))/np.array(real_data_icus[\"total\"]))[validation_days-14:validation_days])\n",
    "error_icus_peak = 0.5*peak_constant*np.nanmean((np.abs(np.array(model_data_icus[\"total\"])-np.array(real_data_icus[\"total\"]))/np.array(real_data_icus[\"total\"]))[peak_icus:peak_icus+1])\n",
    "\n",
    "\n",
    "error_deaths_total = np.nanmean((np.abs(np.array(model_data_deaths[\"total\"])-np.array(real_data_deaths[\"total\"]))/np.array(real_data_deaths[\"total\"]))[0:validation_days-14])\n",
    "error_deaths_tail = tail_constant*np.nanmean((np.abs(np.array(model_data_deaths[\"total\"])-np.array(real_data_deaths[\"total\"]))/np.array(real_data_deaths[\"total\"]))[validation_days-14:validation_days])\n",
    "error_deaths_peak = peak_constant*np.nanmean((np.abs(np.array(model_data_deaths[\"total\"])-np.array(real_data_deaths[\"total\"]))/np.array(real_data_deaths[\"total\"]))[peak_deaths:peak_deaths+1])\n",
    "#         error_deaths_total += error_constant/4.0*np.nanmean((np.abs(np.array(model_data_deaths[\"total\"])-np.array(real_data_deaths[\"total\"]))/np.array(real_data_deaths[\"total\"]))[peak_beds:peak_beds+1])\n",
    "\n",
    "#overflow = np.array(model_data_icus[\"total\"]) - icu_bound\n",
    "#overflow_error = np.nanmean([max(overflow[i],0) for i in range(len(overflow))])\n",
    "\n",
    "\n",
    "upper_days_model = days_model\n",
    "\n",
    "error = error_beds_total+error_beds_tail+error_beds_peak+error_icus_total+error_icus_tail+error_icus_peak+error_deaths_total+error_deaths_tail+error_deaths_peak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../parameters/Ile-de-France.yaml\") as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    universe_params = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "# Modify parameters\n",
    "universe_params['mixing'] = {\n",
    "    \"name\":\"mult\",\n",
    "    \"param_alpha\":float(alpha_mixing),\n",
    "    \"param_beta\":float(alpha_mixing),\n",
    "}\n",
    "universe_params['upper_bounds'] = {\n",
    "    \"transport\":1.0,\n",
    "    \"leisure\":1.0,\n",
    "    \"other\":1.0,\n",
    "    \"school\":1.0,\n",
    "    \"home\":1.0,\n",
    "    \"work\":1.0\n",
    "}\n",
    "# Modify beta\n",
    "for ag in universe_params['seir-groups']:\n",
    "    universe_params['seir-groups'][ag]['parameters']['beta'] = [beta_masks for t in range(360)]\n",
    "\n",
    "new_p_ICU = initial_params[\"p_ICU\"]*fraction_p_ICU\n",
    "new_p_H = (initial_params[\"p_H\"]+initial_params[\"p_ICU\"])-(initial_params[\"p_ICU\"]*fraction_p_ICU)\n",
    "\n",
    "new_lambda_H = initial_params[\"lambda_H\"]*change_lambda_H_aft\n",
    "new_lambda_ICU = initial_params[\"lambda_ICU\"]*change_lambda_ICU_aft\n",
    "new_p_death = initial_params[\"p_death\"]*change_p_death_aft\n",
    "\n",
    "new_lambda_H_D = new_p_death*new_lambda_H\n",
    "new_lambda_H_R = (1-new_p_death)*new_lambda_H\n",
    "new_lambda_ICU_D = new_p_death*new_lambda_ICU\n",
    "new_lambda_ICU_R = (1-new_p_death)*new_lambda_ICU\n",
    "\n",
    "\n",
    "for i,ag in enumerate(age_groups):\n",
    "    universe_params['seir-groups'][ag]['parameters']['p_ICU'] = float(new_p_ICU[i])\n",
    "    universe_params['seir-groups'][ag]['parameters']['p_H'] = float(new_p_H[i])\n",
    "    universe_params['seir-groups'][ag]['parameters']['lambda_H_D'] = float(new_lambda_H_D[i])\n",
    "    universe_params['seir-groups'][ag]['parameters']['lambda_H_R'] = float(new_lambda_H_R[i])\n",
    "    universe_params['seir-groups'][ag]['parameters']['lambda_ICU_D'] = float(new_lambda_ICU_D[i])\n",
    "    universe_params['seir-groups'][ag]['parameters']['lambda_ICU_R'] = float(new_lambda_ICU_R[i])\n",
    "    del universe_params['seir-groups'][ag]['parameters']['p_ICU_cond_ss']\n",
    "    del universe_params['seir-groups'][ag]['parameters']['p_death_cond_ss']\n",
    "    \n",
    "with open('../parameters/fitted.yaml', 'w') as file:\n",
    "    yaml.dump(universe_params, file)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add economic value parameters\n",
    "contrib = pd.read_excel(\"./ile-de-france_data_master.xlsx\",sheet_name=\"contributions_normal\", index_col = 0)\n",
    "gains = pd.read_excel(\"./ile-de-france_data_master.xlsx\",sheet_name=\"activity_levels_as_%_of_full\", index_col = 0)\n",
    "\n",
    "empl_params = {}\n",
    "empl_params[\"v\"] = {}\n",
    "for age_group in age_groups:\n",
    "    empl_params[\"v\"][age_group] = {}\n",
    "    for activity in econ_activities:\n",
    "        empl_params[\"v\"][age_group][activity] = float(contrib[age_group][activity])/365.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "april 0.2131333333333333\n",
      "may 0.36496774193548387\n",
      "Using license file /Users/sergioacamelogomez/gurobi.lic\n",
      "Academic license - for non-commercial use only\n",
      "Gurobi Optimizer version 9.0.2 build v9.0.2rc0 (mac64)\n",
      "Optimize a model with 2 rows, 4 columns and 6 nonzeros\n",
      "Model fingerprint: 0xd6780599\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-01, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [6e-01, 1e+00]\n",
      "Presolve removed 1 rows and 1 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 1 rows, 3 columns, 3 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "       0    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "nu 0.5009171397102432\n",
      "eta 0.026364059984749645\n",
      "gamma 0.4727188003050071\n"
     ]
    }
   ],
   "source": [
    "from gurobipy import *\n",
    "\n",
    "# Calculate l-april and l-may\n",
    "l_april = np.mean([google['work'][i] for i in range(len(google)) if google['date'][i][0:7]==\"2020-04\"])\n",
    "l_may = np.mean([google['work'][i] for i in range(len(google)) if google['date'][i][0:7]==\"2020-05\"])\n",
    "print(\"april\",l_april)\n",
    "print(\"may\",l_may)\n",
    "\n",
    "\n",
    "eq_activities = ['leisure','other','school','transport']\n",
    "\n",
    "m = Model()\n",
    "nu = m.addVar(vtype=GRB.CONTINUOUS, name=\"nu\", lb = 0)\n",
    "gamma = m.addVar(vtype=GRB.CONTINUOUS, name=\"gamma\", lb = 0)\n",
    "epsilonp_1 = m.addVar(vtype=GRB.CONTINUOUS, name=\"epsilonp_1\", lb = 0)\n",
    "epsilonn_1 = m.addVar(vtype=GRB.CONTINUOUS, name=\"epsilonn_1\", lb = 0)\n",
    "\n",
    "m.addConstr(nu+gamma==1)\n",
    "m.addConstr(\n",
    "        nu*l_april  + gamma == 0.5851+epsilonp_1-epsilonn_1\n",
    ")\n",
    "\n",
    "m.setObjective(epsilonp_1+epsilonn_1)\n",
    "m.update()\n",
    "m.optimize()\n",
    "\n",
    "empl_params['nu'] = 0.95*float(nu.x)\n",
    "empl_params['gamma'] = float(gamma.x)\n",
    "empl_params['eta'] = 0.05*float(nu.x)\n",
    "\n",
    "print(\"nu\",empl_params['nu'])\n",
    "print(\"eta\",empl_params['eta'])\n",
    "print(\"gamma\",empl_params['gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the schooling parameter\n",
    "r = 0.03\n",
    "schooling_param = {}\n",
    "for age_group in age_groups:\n",
    "    if age_group == \"age_group_0_9\":\n",
    "        schooling_param[age_group] = (1+r)**(-15)*sum([empl_params[\"v\"][\"age_group_20_29\"][act] for act in econ_activities])\n",
    "    elif age_group == \"age_group_10_19\":\n",
    "        schooling_param[age_group] = 0.907*(1+r)**(-5)*sum([empl_params[\"v\"][\"age_group_20_29\"][act] for act in econ_activities])\n",
    "    else:\n",
    "        schooling_param[age_group] = 0\n",
    "        \n",
    "# Calculate the cost of death\n",
    "econ_cost_death = {}\n",
    "age_groups_n = [0,10,20,30,40,50,60,70,80]\n",
    "for i,age_group in enumerate(age_groups):\n",
    "    s = 0\n",
    "    for tao in range(age_groups_n[i]+5,70):\n",
    "        ag = \"age_group_%d_%d\"%(int(tao/10)*10,int(tao/10)*10+9)\n",
    "        s+=(1+r)**(-(tao-age_groups_n[i]))*sum([empl_params[\"v\"][ag][act] for act in econ_activities])*365\n",
    "    econ_cost_death[age_group] = float(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_bounds = {\n",
    "    \"transport\":1.0,\n",
    "    \"leisure\":1.0,\n",
    "    \"other\":1.0,\n",
    "    \"school\":1.0,\n",
    "    \"home\":1.0,\n",
    "    \"work\":1.0\n",
    "}\n",
    "\n",
    "econ_params = {\n",
    "    \"employment_params\":empl_params,\n",
    "    \"schooling_params\":schooling_param,\n",
    "    \"econ_cost_death\":econ_cost_death,\n",
    "    \"upper_bounds\":upper_bounds,\n",
    "}\n",
    "with open('../parameters/econ.yaml', 'w') as file:\n",
    "    yaml.dump(econ_params, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_state(m):\n",
    "    state = {}\n",
    "    for i,age_group in enumerate(age_groups):\n",
    "        state[age_group] = {}\n",
    "        for j,c in enumerate(cont):\n",
    "            state[age_group][c] = float(m[i,j])\n",
    "    return state\n",
    "\n",
    "with open('../initialization/oct21.yaml', 'w') as file:\n",
    "    yaml.dump(matrix_to_state(final_state), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
