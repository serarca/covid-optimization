{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from stable_baselines.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_covid.envs.covid_env import CovidEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CovidEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines import DQN, PPO2, A2C, ACKTR\n",
    "from stable_baselines.common.cmd_util import make_vec_env\n",
    "\n",
    "# Instantiate the env\n",
    "env = CovidEnv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68681269380.9298\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "a = 1\n",
    "rewards = 0\n",
    "while True:\n",
    "    obs, reward, done, info = env.step([1,1,1,1,1,1])\n",
    "    rewards += reward\n",
    "    if done:\n",
    "        break\n",
    "print(rewards)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1a4e5f5950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1a4e5f5950>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1a4e5f5950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1a4e5f5950>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1a4b592d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1a4b592d10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1a4b592d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1a4b592d10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /Users/sergioacamelogomez/opt/anaconda3/lib/python3.7/site-packages/stable_baselines/a2c/a2c.py:182: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sergioacamelogomez/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "| explained_variance | 0        |\n",
      "| fps                | 10       |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 9.66     |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 8.66e+19 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | -3.95e+10 |\n",
      "| explained_variance | 0         |\n",
      "| fps                | 46        |\n",
      "| nupdates           | 100       |\n",
      "| policy_entropy     | 9.66      |\n",
      "| total_timesteps    | 500       |\n",
      "| value_loss         | 7.49e+19  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | -4.86e+10 |\n",
      "| explained_variance | 0         |\n",
      "| fps                | 46        |\n",
      "| nupdates           | 200       |\n",
      "| policy_entropy     | 9.66      |\n",
      "| total_timesteps    | 1000      |\n",
      "| value_loss         | 3.05e+21  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | -4.67e+10 |\n",
      "| explained_variance | 0         |\n",
      "| fps                | 47        |\n",
      "| nupdates           | 300       |\n",
      "| policy_entropy     | 9.66      |\n",
      "| total_timesteps    | 1500      |\n",
      "| value_loss         | 2.03e+18  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | -4.79e+10 |\n",
      "| explained_variance | 0         |\n",
      "| fps                | 48        |\n",
      "| nupdates           | 400       |\n",
      "| policy_entropy     | 9.66      |\n",
      "| total_timesteps    | 2000      |\n",
      "| value_loss         | 8.8e+20   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | -4.62e+10 |\n",
      "| explained_variance | 0         |\n",
      "| fps                | 48        |\n",
      "| nupdates           | 500       |\n",
      "| policy_entropy     | 9.66      |\n",
      "| total_timesteps    | 2500      |\n",
      "| value_loss         | 5.13e+19  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | -4.68e+10 |\n",
      "| explained_variance | 0         |\n",
      "| fps                | 48        |\n",
      "| nupdates           | 600       |\n",
      "| policy_entropy     | 9.66      |\n",
      "| total_timesteps    | 3000      |\n",
      "| value_loss         | 9.19e+18  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | -4.39e+10 |\n",
      "| explained_variance | 0         |\n",
      "| fps                | 48        |\n",
      "| nupdates           | 700       |\n",
      "| policy_entropy     | 9.65      |\n",
      "| total_timesteps    | 3500      |\n",
      "| value_loss         | 7.48e+20  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | -4.21e+10 |\n",
      "| explained_variance | 0         |\n",
      "| fps                | 48        |\n",
      "| nupdates           | 800       |\n",
      "| policy_entropy     | 9.65      |\n",
      "| total_timesteps    | 4000      |\n",
      "| value_loss         | 7.42e+19  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | -3.68e+10 |\n",
      "| explained_variance | 0         |\n",
      "| fps                | 48        |\n",
      "| nupdates           | 900       |\n",
      "| policy_entropy     | 9.65      |\n",
      "| total_timesteps    | 4500      |\n",
      "| value_loss         | 2.01e+19  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | -3.26e+10 |\n",
      "| explained_variance | 0         |\n",
      "| fps                | 48        |\n",
      "| nupdates           | 1000      |\n",
      "| policy_entropy     | 9.65      |\n",
      "| total_timesteps    | 5000      |\n",
      "| value_loss         | 3.97e+20  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | -2.82e+10 |\n",
      "| explained_variance | 0         |\n",
      "| fps                | 48        |\n",
      "| nupdates           | 1100      |\n",
      "| policy_entropy     | 9.62      |\n",
      "| total_timesteps    | 5500      |\n",
      "| value_loss         | 5.04e+20  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | -2.39e+10 |\n",
      "| explained_variance | 0         |\n",
      "| fps                | 48        |\n",
      "| nupdates           | 1200      |\n",
      "| policy_entropy     | 9.61      |\n",
      "| total_timesteps    | 6000      |\n",
      "| value_loss         | 2.47e+18  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | -1.97e+10 |\n",
      "| explained_variance | 0         |\n",
      "| fps                | 48        |\n",
      "| nupdates           | 1300      |\n",
      "| policy_entropy     | 9.49      |\n",
      "| total_timesteps    | 6500      |\n",
      "| value_loss         | 1.21e+19  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | -1.58e+10 |\n",
      "| explained_variance | 0         |\n",
      "| fps                | 48        |\n",
      "| nupdates           | 1400      |\n",
      "| policy_entropy     | 9.55      |\n",
      "| total_timesteps    | 7000      |\n",
      "| value_loss         | 7.74e+19  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | -8.64e+09 |\n",
      "| explained_variance | 0         |\n",
      "| fps                | 49        |\n",
      "| nupdates           | 1500      |\n",
      "| policy_entropy     | 9.41      |\n",
      "| total_timesteps    | 7500      |\n",
      "| value_loss         | 4e+19     |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 9.85e+07 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 49       |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 9.31     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 3.63e+18 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 1.05e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 49       |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 9.26     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 1.47e+18 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 1.85e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 9.44     |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 4.16e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 2.44e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 9.37     |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 6.03e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 2.84e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 9.23     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 6.56e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 3.06e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 2100     |\n",
      "| policy_entropy     | 8.99     |\n",
      "| total_timesteps    | 10500    |\n",
      "| value_loss         | 3.88e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 3.66e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 2200     |\n",
      "| policy_entropy     | 8.99     |\n",
      "| total_timesteps    | 11000    |\n",
      "| value_loss         | 1.74e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 4.13e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 2300     |\n",
      "| policy_entropy     | 9.1      |\n",
      "| total_timesteps    | 11500    |\n",
      "| value_loss         | 8.25e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 4.68e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 2400     |\n",
      "| policy_entropy     | 8.8      |\n",
      "| total_timesteps    | 12000    |\n",
      "| value_loss         | 7.55e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.19e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 49       |\n",
      "| nupdates           | 2500     |\n",
      "| policy_entropy     | 8.83     |\n",
      "| total_timesteps    | 12500    |\n",
      "| value_loss         | 7.57e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.43e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 49       |\n",
      "| nupdates           | 2600     |\n",
      "| policy_entropy     | 8.59     |\n",
      "| total_timesteps    | 13000    |\n",
      "| value_loss         | 7.1e+19  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.42e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 49       |\n",
      "| nupdates           | 2700     |\n",
      "| policy_entropy     | 9.16     |\n",
      "| total_timesteps    | 13500    |\n",
      "| value_loss         | 7.57e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.5e+10  |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 49       |\n",
      "| nupdates           | 2800     |\n",
      "| policy_entropy     | 9.05     |\n",
      "| total_timesteps    | 14000    |\n",
      "| value_loss         | 6.13e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 4.97e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 49       |\n",
      "| nupdates           | 2900     |\n",
      "| policy_entropy     | 8.97     |\n",
      "| total_timesteps    | 14500    |\n",
      "| value_loss         | 7.74e+19 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | 4.75e+10  |\n",
      "| explained_variance | -1.19e-07 |\n",
      "| fps                | 49        |\n",
      "| nupdates           | 3000      |\n",
      "| policy_entropy     | 8.46      |\n",
      "| total_timesteps    | 15000     |\n",
      "| value_loss         | 9.71e+18  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.12e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 49       |\n",
      "| nupdates           | 3100     |\n",
      "| policy_entropy     | 8.72     |\n",
      "| total_timesteps    | 15500    |\n",
      "| value_loss         | 5.89e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.34e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 49       |\n",
      "| nupdates           | 3200     |\n",
      "| policy_entropy     | 8.51     |\n",
      "| total_timesteps    | 16000    |\n",
      "| value_loss         | 7.48e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.45e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 49       |\n",
      "| nupdates           | 3300     |\n",
      "| policy_entropy     | 8.46     |\n",
      "| total_timesteps    | 16500    |\n",
      "| value_loss         | 6.11e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.88e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 49       |\n",
      "| nupdates           | 3400     |\n",
      "| policy_entropy     | 8.08     |\n",
      "| total_timesteps    | 17000    |\n",
      "| value_loss         | 8.1e+19  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 6.36e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 3500     |\n",
      "| policy_entropy     | 8.43     |\n",
      "| total_timesteps    | 17500    |\n",
      "| value_loss         | 2.75e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 6.13e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 3600     |\n",
      "| policy_entropy     | 9.04     |\n",
      "| total_timesteps    | 18000    |\n",
      "| value_loss         | 9.17e+19 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | 5.58e+10  |\n",
      "| explained_variance | -1.19e-07 |\n",
      "| fps                | 48        |\n",
      "| nupdates           | 3700      |\n",
      "| policy_entropy     | 8.86      |\n",
      "| total_timesteps    | 18500     |\n",
      "| value_loss         | 3.73e+17  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.59e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 3800     |\n",
      "| policy_entropy     | 8.62     |\n",
      "| total_timesteps    | 19000    |\n",
      "| value_loss         | 7.17e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.53e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 3900     |\n",
      "| policy_entropy     | 8.06     |\n",
      "| total_timesteps    | 19500    |\n",
      "| value_loss         | 6.48e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.1e+10  |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 4000     |\n",
      "| policy_entropy     | 9.25     |\n",
      "| total_timesteps    | 20000    |\n",
      "| value_loss         | 4.43e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.04e+10 |\n",
      "| explained_variance | 5.96e-08 |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 4100     |\n",
      "| policy_entropy     | 8.95     |\n",
      "| total_timesteps    | 20500    |\n",
      "| value_loss         | 6.75e+18 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.19e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 4200     |\n",
      "| policy_entropy     | 8.7      |\n",
      "| total_timesteps    | 21000    |\n",
      "| value_loss         | 5.25e+18 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.26e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 4300     |\n",
      "| policy_entropy     | 8.44     |\n",
      "| total_timesteps    | 21500    |\n",
      "| value_loss         | 5.87e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.19e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 4400     |\n",
      "| policy_entropy     | 9.14     |\n",
      "| total_timesteps    | 22000    |\n",
      "| value_loss         | 6.09e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.53e+10 |\n",
      "| explained_variance | 1.19e-07 |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 4500     |\n",
      "| policy_entropy     | 9.07     |\n",
      "| total_timesteps    | 22500    |\n",
      "| value_loss         | 3.8e+18  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.49e+10 |\n",
      "| explained_variance | 1.19e-07 |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 4600     |\n",
      "| policy_entropy     | 8.96     |\n",
      "| total_timesteps    | 23000    |\n",
      "| value_loss         | 1.28e+19 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | 5.57e+10  |\n",
      "| explained_variance | -1.19e-07 |\n",
      "| fps                | 48        |\n",
      "| nupdates           | 4700      |\n",
      "| policy_entropy     | 8.52      |\n",
      "| total_timesteps    | 23500     |\n",
      "| value_loss         | 1.28e+19  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | 5.43e+10  |\n",
      "| explained_variance | -1.19e-07 |\n",
      "| fps                | 48        |\n",
      "| nupdates           | 4800      |\n",
      "| policy_entropy     | 8.66      |\n",
      "| total_timesteps    | 24000     |\n",
      "| value_loss         | 3.52e+19  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.43e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 4900     |\n",
      "| policy_entropy     | 9.17     |\n",
      "| total_timesteps    | 24500    |\n",
      "| value_loss         | 6.42e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.37e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 5000     |\n",
      "| policy_entropy     | 8.65     |\n",
      "| total_timesteps    | 25000    |\n",
      "| value_loss         | 6.75e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.62e+10 |\n",
      "| explained_variance | 1.19e-07 |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 5100     |\n",
      "| policy_entropy     | 7.77     |\n",
      "| total_timesteps    | 25500    |\n",
      "| value_loss         | 2.68e+18 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.77e+10 |\n",
      "| explained_variance | 1.19e-07 |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 5200     |\n",
      "| policy_entropy     | 7.89     |\n",
      "| total_timesteps    | 26000    |\n",
      "| value_loss         | 7.98e+18 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.86e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 5300     |\n",
      "| policy_entropy     | 9.13     |\n",
      "| total_timesteps    | 26500    |\n",
      "| value_loss         | 1.09e+20 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | 5.76e+10  |\n",
      "| explained_variance | -1.19e-07 |\n",
      "| fps                | 48        |\n",
      "| nupdates           | 5400      |\n",
      "| policy_entropy     | 8.9       |\n",
      "| total_timesteps    | 27000     |\n",
      "| value_loss         | 3.1e+17   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.83e+10 |\n",
      "| explained_variance | 1.19e-07 |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 5500     |\n",
      "| policy_entropy     | 8.63     |\n",
      "| total_timesteps    | 27500    |\n",
      "| value_loss         | 1.08e+19 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | 5.78e+10  |\n",
      "| explained_variance | -1.19e-07 |\n",
      "| fps                | 48        |\n",
      "| nupdates           | 5600      |\n",
      "| policy_entropy     | 8.03      |\n",
      "| total_timesteps    | 28000     |\n",
      "| value_loss         | 6.02e+19  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | 5.54e+10  |\n",
      "| explained_variance | -1.19e-07 |\n",
      "| fps                | 48        |\n",
      "| nupdates           | 5700      |\n",
      "| policy_entropy     | 8.6       |\n",
      "| total_timesteps    | 28500     |\n",
      "| value_loss         | 4.84e+19  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 26        |\n",
      "| ep_reward_mean     | 5.65e+10  |\n",
      "| explained_variance | -1.19e-07 |\n",
      "| fps                | 48        |\n",
      "| nupdates           | 5800      |\n",
      "| policy_entropy     | 8.79      |\n",
      "| total_timesteps    | 29000     |\n",
      "| value_loss         | 7.89e+19  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.67e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 5900     |\n",
      "| policy_entropy     | 7.95     |\n",
      "| total_timesteps    | 29500    |\n",
      "| value_loss         | 7.95e+19 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 26       |\n",
      "| ep_reward_mean     | 5.86e+10 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 48       |\n",
      "| nupdates           | 6000     |\n",
      "| policy_entropy     | 7.47     |\n",
      "| total_timesteps    | 30000    |\n",
      "| value_loss         | 9.69e+19 |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# wrap it\n",
    "env = make_vec_env(lambda: env, n_envs=1)\n",
    "model = A2C('MlpLnLstmPolicy', env, verbose=1).learn(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 2 3 2 0]]\n",
      "[[1 0 2 3 2 0]]\n",
      "[[1 0 2 3 2 0]]\n",
      "[[1 0 2 1 2 0]]\n",
      "[[1 0 2 1 2 0]]\n",
      "[[1 0 2 1 2 0]]\n",
      "[[1 0 2 1 2 0]]\n",
      "[[1 0 2 1 2 0]]\n",
      "[[1 0 2 1 2 0]]\n",
      "[[1 0 1 1 2 0]]\n",
      "[[1 0 1 1 2 0]]\n",
      "[[1 0 1 1 2 0]]\n",
      "[[1 0 1 1 2 0]]\n",
      "[[1 0 1 1 2 0]]\n",
      "[[1 0 1 1 2 0]]\n",
      "[[1 0 1 1 2 0]]\n",
      "[[1 0 1 1 2 0]]\n",
      "[[1 0 1 1 2 0]]\n",
      "[[1 0 1 1 2 0]]\n",
      "[[1 0 1 1 2 0]]\n",
      "[[1 0 1 1 2 0]]\n",
      "[[1 0 1 1 2 0]]\n",
      "[[1 0 1 1 2 0]]\n",
      "[[1 0 1 1 2 0]]\n",
      "[[1 0 1 1 2 0]]\n",
      "[[1 0 1 1 2 0]]\n",
      "[7.4015875e+10]\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "a = 1\n",
    "rewards = 0\n",
    "while True:\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    rewards += reward\n",
    "    print(action)\n",
    "    if done:\n",
    "        break\n",
    "print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"a2c_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
